{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73625e66-d7eb-413f-b9a2-8d016725c34f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac4251f-16fd-4fbb-bb5a-3c83ac2f0977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Shopee/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cf4bcf-7467-4536-8f33-4e6d4516af68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11011/11011 [07:47<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32412 11011\n",
      "--->>>\n",
      "17868 3734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1646767365</td>\n",
       "      <td>1d7aadc7503b2b4539cc9a5fe41979dd.jpg</td>\n",
       "      <td>e925873ed09cd08f</td>\n",
       "      <td>Sarung celana wadimor original 100% dewasa dan...</td>\n",
       "      <td>258047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0  train_1646767365  1d7aadc7503b2b4539cc9a5fe41979dd.jpg  e925873ed09cd08f   \n",
       "\n",
       "                                               title  label_group  \n",
       "0  Sarung celana wadimor original 100% dewasa dan...       258047  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Shopee/train.csv')\n",
    "df.drop_duplicates(subset='image', inplace=True)\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('label_group')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "#     elif len(group)>100:\n",
    "#         group = group.sample(100)\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        file = row['image']\n",
    "        path = 'autodl-tmp/ori_data/Shopee/train_images/'+file\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "#             img = A.CenterCrop(min_, min_)(image=img)['image']\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "#             img = A.CenterCrop(min_, min_)(image=img)['image']\n",
    "        new_path = 'autodl-tmp/final_data_224/Shopee/images/'+file\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Shopee/Shopee_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Shopee/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['label_group'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['label_group'].nunique())\n",
    "df_n100_224.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b89f5-3fa7-4ada-b59f-7cf904f13e6b",
   "metadata": {},
   "source": [
    "#### Landmark-GLDV2-clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c197d5-c961-4d9c-a5eb-69aeb4667b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Landmark2021/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9874ece-f64a-4ee1-ba5e-0aeef9ecc2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Landmark2021/train.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('landmark_id')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index()\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        file = row['id']\n",
    "        path = f'autodl-tmp/ori_data/Landmark2021/train/{file[0]}/{file[1]}/{file[2]}/{file}.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Landmark2021/images/'+f'{file}.jpg'\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.drop(columns=['index'], inplace=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Landmark2021/Landmark2021_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Landmark2021/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['landmark_id'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['landmark_id'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a8fb9-0ed9-42c6-82f6-b792da59c7b4",
   "metadata": {},
   "source": [
    "#### JD-product-10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d4f82-4954-4cc1-81eb-8e925b767da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/JD_Products_10K/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4426bcb-f39a-4561-9f22-b50282a49098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/JD_Products_10K/JD_product10K_train.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('class')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        file = row['name']\n",
    "        path = f'autodl-tmp/ori_data/JD_Products_10K/train/{file}'\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/JD_Products_10K/images/'+f'{file}'\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/JD_Products_10K/JD_product10K_final_224.csv', index=False)\n",
    "all_files = glob('autodl-tmp/final_data_224/JD_Products_10K/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['class'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['class'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d379cbe-90d4-45ee-bdfc-7941a9fa4ed6",
   "metadata": {},
   "source": [
    "#### Art_MET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e7ada-64b9-4890-9228-7ce05db13d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Art_MET/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6010c25-9428-4f1f-a0cf-71bfb2597cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Art_MET/Art_MET.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Art_MET/images/'+path.split('/')[-2]+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = path.split('/')[-2]+path.split('/')[-1]\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Art_MET/Art_MET_final_224.csv', index=False)\n",
    "all_files = glob('autodl-tmp/final_data_224/Art_MET/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79596713-511a-4ee0-aa3b-3d74bd438994",
   "metadata": {},
   "source": [
    "#### Ali_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9d2c7-9220-49cc-9fa0-8a5e46e5ced4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Aliproducts/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee0694-0185-4a19-9470-04d97874f4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Aliproducts/Aliproducts.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Aliproducts/images/'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Aliproducts/Aliproducts_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Aliproducts/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a245076-4d8c-477e-9c81-c589c49a3ca3",
   "metadata": {},
   "source": [
    "#### Stanford_Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09b1c7-cc7d-4ee7-872b-8dd0751b7aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Stanford_Cars/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa245c49-a3ea-455a-9675-aeb8dbca6808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Stanford_Cars/Stanford_Cars.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = 'autodl-tmp/ori_data/Stanford_Cars/'+row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Stanford_Cars/images/'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Stanford_Cars/Stanford_Cars_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Stanford_Cars/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12af9a-4188-4f9a-8a6b-c68b78ea245a",
   "metadata": {},
   "source": [
    "#### Stanford_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928fbf0-bbb4-4008-88ad-831d20aa4245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Stanford_Products/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90f656-2bd7-47e9-8310-44ab57a1eef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Stanford_Products/Stanford_Products.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Stanford_Products/images/'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Stanford_Products/Stanford_Products_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Stanford_Products/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe85fa0-9e12-42ee-a124-7d4981aea5ef",
   "metadata": {},
   "source": [
    "#### Deep Fashion （Consumer-to-shop）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8bfa1-d406-4121-b79d-057a236d5d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/DeepFashion_CTS/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130471b-ed9a-4189-9324-2666e4a37337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/DeepFashion_CTS/DeepFashion_CTS.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/DeepFashion_CTS/images/'+f'f_{label}_{idx}_'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/DeepFashion_CTS/DeepFashion_CTS_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/DeepFashion_CTS/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0],(len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0456d-18f5-4c41-bb19-c4c45e5e1894",
   "metadata": {},
   "source": [
    "#### Fruit （Grocery Store）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb913b-0d57-4bbf-a8c3-36080fd1326a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Fruit/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9bdf3-d82c-46fa-91f6-e84a88f00350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Fruit/Fruit.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    all_groups.append(group)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Fruit/images/'+path.split('/')[-4]+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Fruit/Fruit_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Fruit/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0]\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146ed61-d5e7-4543-818b-2b3bed41ec4c",
   "metadata": {},
   "source": [
    "#### Fashion200K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62728504-271e-478a-9ef2-abee5b49a7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Fashion_200K/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6cd92-b34e-449d-ad71-d3a64ced4823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Fashion_200K/Fashion_200K.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Fashion_200K/images/'+path.split('/')[-3]+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Fashion_200K/Fashion_200K_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Fashion_200K/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06326d-b7c6-4aa5-b8b4-55b19ed5ad82",
   "metadata": {},
   "source": [
    "#### Food2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71c4a5-f67c-450c-bbf3-1d31ba596c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Food2022/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a3730-cdfd-45af-a0e0-89791f3667d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Food2022/food_first.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    for idx, row in group.iterrows():\n",
    "        file = row['image_files']\n",
    "        path = file.replace('autodl-tmp', 'autodl-tmp/ori_data/Food2022')\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Food2022/images/'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Food2022/Food2022_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Food2022/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d15f7-deb9-4c25-86c4-bccb363fc63e",
   "metadata": {},
   "source": [
    "### RP2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156b4ce-d02e-41b5-b24a-acd68398df7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/rp2k/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e67ea-cb13-4113-8cec-702cd1f66f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/rp2k/rp2k.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/rp2k/images/'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/rp2k/rp2k_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/rp2k/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e4a3c-e456-41f3-a8c1-d8beeeaf4551",
   "metadata": {},
   "source": [
    "### DeepFashion2 （hard-triplets）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af7aad-dbbf-4191-acf4-1bc258fbe4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/DeepFashion2/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c801c7-64b9-4656-b579-988f9998f2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/DeepFashion2/DeepFashion2.csv')\n",
    "all_groups = []\n",
    "n = 0\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<3:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = f'autodl-tmp/final_data_224/DeepFashion2/images/{n}_'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "        n+=1\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/DeepFashion2/DeepFashion2_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/DeepFashion2/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique(), df_n100_224['image_files'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d94960-04e6-4ab4-9e59-3c3a89548afe",
   "metadata": {},
   "source": [
    "### Food2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7be32f-b7f6-4606-bf66-a1c912b17dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, trange\n",
    "import albumentations as A\n",
    "os.makedirs('autodl-tmp/final_data_224/Food2021/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018bb2dd-2d02-4b1c-b3c9-6cabcccd06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('autodl-tmp/ori_data/Food2021/Food2021.csv')\n",
    "all_groups = []\n",
    "for label, group in tqdm(df.groupby('labels')):\n",
    "    if len(group)<5:\n",
    "        continue\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        path = row['image_files']\n",
    "        img = cv2.imread(path)\n",
    "        min_ = min(img.shape[:2])\n",
    "        max_ = max(img.shape[:2])\n",
    "        if min_>224:\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        elif max_>224:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        new_path = 'autodl-tmp/final_data_224/Food2021/images/'+path.split('/')[-1]\n",
    "        cv2.imwrite(new_path, img)\n",
    "        group.loc[idx, 'image_files'] = new_path\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_n100_224 = pd.concat(all_groups, axis=0).reset_index(drop=True)\n",
    "df_n100_224.to_csv('autodl-tmp/final_data_224/Food2021/Food2021_final_224.csv', index=False)\n",
    "\n",
    "all_files = glob('autodl-tmp/final_data_224/Food2021/images/*')\n",
    "assert len(all_files)==df_n100_224.shape[0], (len(all_files), df_n100_224.shape[0])\n",
    "print(df.shape[0], df['labels'].nunique())\n",
    "print('--->>>')\n",
    "print(df_n100_224.shape[0], df_n100_224['labels'].nunique())\n",
    "df_n100_224.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de3fc3-ead0-433c-be08-fb55743cd631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
